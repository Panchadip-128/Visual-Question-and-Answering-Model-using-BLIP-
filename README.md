# Visual-Question-and-Answering-Model
This repository contains an implementation of a Visual Question Answering (VQA) model built using the BLIP (Bootstrapping Language-Image Pre-training) framework. This model can understand image content and answer questions related to the provided images.
A tool that reads an image based on ML algorithms( BLIP model) and implements VQA which answers questions based on user prompts for the image, deployed through Gradio web application..
